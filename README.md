# üß† Agent With Memory (AWM 2.0)

**Production-ready AI memory system for any agent.** Built on MongoDB Atlas Vector Search.

## üéØ What This Is

A **plug-and-play memory layer** that gives any AI agent persistent memory across sessions. Your agent remembers users, learns from interactions, and builds knowledge over time.

**Without memory**: ChatGPT that forgets everything.
**With memory**: A true AI agent that learns and grows.

## ‚ö° Quick Start (5 Minutes)

```bash
# 1. Clone
git clone https://github.com/romiluz13/agent_with_memory.git
cd agent_with_memory

# 2. Setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. Configure (create .env file)
MONGODB_URI=mongodb+srv://...
VOYAGE_API_KEY=pa-...
GOOGLE_API_KEY=AIza...

# 4. Run the demo
python demo_memory_agent.py
```

The demo proves memory works across sessions:
- **Session 1**: Tell the agent your name, job, pet, etc.
- **Session 2**: NEW session asks what it remembers ‚Üí It recalls everything!

## üîå Plug & Play - Add Memory to ANY Agent

```python
from src.memory.manager import MemoryManager
from src.memory.base import MemoryType
from src.storage.mongodb_client import MongoDBClient, MongoDBConfig

# 1. Connect to MongoDB
config = MongoDBConfig(uri="mongodb+srv://...", database="my_app")
db_client = MongoDBClient()
await db_client.initialize(config)

# 2. Create Memory Manager
memory = MemoryManager(db_client.db)

# 3. Store memories (from your agent's conversations)
await memory.store_memory(
    content="User said they love Python and work at Google",
    memory_type=MemoryType.EPISODIC,
    agent_id="my_agent",
    user_id="user_123"
)

# 4. Retrieve relevant memories (before responding)
memories = await memory.episodic.retrieve(
    query="What programming language does the user like?",
    agent_id="my_agent",
    user_id="user_123",
    limit=5
)

# 5. Use memories in your agent's context
for mem in memories:
    print(f"Remembered: {mem.content}")
```

**That's it!** 5 lines to add persistent memory to any agent.

## üß† 7-Type Memory System

| Type | Purpose | Example |
|------|---------|---------|
| **EPISODIC** | Conversation history | "User asked about Python tutorials" |
| **SEMANTIC** | Facts & knowledge | "MongoDB supports vector search" |
| **PROCEDURAL** | How-to workflows | "To deploy: build ‚Üí push ‚Üí update" |
| **WORKING** | Current session context | "Currently helping with optimization" |
| **CACHE** | Fast retrieval | Frequently accessed data |
| **ENTITY** | People, places, things | "John works at Google" |
| **SUMMARY** | Compressed context | Condensed conversation summaries |

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Your Agent (Any Framework)       ‚îÇ
‚îÇ   LangChain, LangGraph, Custom, etc.    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           MemoryManager                  ‚îÇ
‚îÇ   ‚Ä¢ store_memory()                       ‚îÇ
‚îÇ   ‚Ä¢ retrieve_memories()                  ‚îÇ
‚îÇ   ‚Ä¢ extract_entities()                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     MongoDB Atlas + Vector Search        ‚îÇ
‚îÇ   ‚Ä¢ Voyage AI Embeddings (1024 dims)    ‚îÇ
‚îÇ   ‚Ä¢ Hybrid Search (vector + full-text)  ‚îÇ
‚îÇ   ‚Ä¢ Multi-tenant Isolation              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Project Structure

```
agent_with_memory/
‚îú‚îÄ‚îÄ demo_memory_agent.py    # üöÄ START HERE - Real-life demo
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ setup_indexes.py    # Create vector + text indexes
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ memory/             # 7-type memory system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager.py      # Main orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ episodic.py     # Conversation history
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic.py     # Facts & knowledge
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ procedural.py   # Workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ working.py      # Session context
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py        # Fast retrieval
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity.py       # Entity extraction
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary.py      # Context compression
‚îÇ   ‚îú‚îÄ‚îÄ context/            # Token management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engineer.py     # Auto-compression at 80%
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summarizer.py   # LLM summarization
‚îÇ   ‚îú‚îÄ‚îÄ storage/            # MongoDB integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mongodb_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_index.py
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/         # Voyage AI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ voyage_client.py
‚îÇ   ‚îî‚îÄ‚îÄ retrieval/          # Hybrid search ($rankFusion)
‚îÇ       ‚îî‚îÄ‚îÄ vector_search.py
‚îú‚îÄ‚îÄ tests/                  # Comprehensive test suite
‚îî‚îÄ‚îÄ CLAUDE.md               # Project documentation
```

## üîß Key Features

### Multi-Tenant Isolation
Each agent and user has isolated memories:
```python
# Agent A's memories are separate from Agent B's
await memory.store_memory(..., agent_id="agent_a", user_id="user_1")
await memory.store_memory(..., agent_id="agent_b", user_id="user_1")
```

### Entity Extraction
Automatically extract people, organizations, locations:
```python
entities = await memory.extract_entities(
    text="I'm John, a software engineer at Google",
    agent_id="my_agent",
    llm=your_llm
)
# Returns: [{"name": "John", "type": "PERSON"}, {"name": "Google", "type": "ORGANIZATION"}]
```

### Context Compression
Auto-compress when context gets too long:
```python
from src.context.engineer import ContextEngineer

engineer = ContextEngineer()
if engineer.should_compress(context, model="gpt-4"):
    compressed = await engineer.compress(context, llm)
```

### Hybrid Search (Vector + Full-Text)
Find relevant memories using MongoDB's `$rankFusion` for best results:
```python
# Hybrid search is the DEFAULT - combines semantic + keyword matching
memories = await memory.episodic.retrieve(
    query="What does the user like?",
    agent_id="my_agent",
    user_id="user_123",
    limit=5,
    threshold=0.5,
    search_mode="hybrid"  # Default - can also use "semantic" or "text"
)
```

**Why hybrid?**
- "John" ‚Üí Exact keyword match finds the person
- "software developer" ‚Üí Semantic similarity finds "engineer"
- Combined ‚Üí Best of both worlds

## üß™ Testing

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific tests
python -m pytest tests/integration/test_multi_tenant_isolation.py -v
python -m pytest tests/integration/test_entity_extraction.py -v
```

## üìù Environment Variables

```bash
# Required
MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net/
VOYAGE_API_KEY=pa-...          # For embeddings
GOOGLE_API_KEY=AIza...         # For LLM (or use OpenAI)

# Optional
OPENAI_API_KEY=sk-...          # Alternative LLM
ANTHROPIC_API_KEY=sk-ant-...   # Alternative LLM
```

## üöÄ MongoDB Atlas Setup

1. Create a [MongoDB Atlas](https://www.mongodb.com/atlas) account (free tier works!)
2. Create a cluster
3. Get your connection string
4. Run the setup script to create indexes:

```bash
# Create all required indexes (vector + text for hybrid search)
python scripts/setup_indexes.py
```

### Search Indexes

The setup script creates **14 indexes** (7 vector + 7 text) for hybrid search:

**Vector Index** (for semantic similarity):
```json
{
  "name": "vector_index",
  "type": "vectorSearch",
  "definition": {
    "fields": [
      {"type": "vector", "path": "embedding", "similarity": "cosine", "numDimensions": 1024},
      {"type": "filter", "path": "agent_id"},
      {"type": "filter", "path": "user_id"}
    ]
  }
}
```

**Text Index** (for keyword matching):
```json
{
  "name": "text_search_index",
  "type": "search",
  "definition": {
    "mappings": {
      "fields": {
        "content": {"type": "string", "analyzer": "lucene.standard"},
        "agent_id": {"type": "string"},
        "user_id": {"type": "string"}
      }
    }
  }
}
```

> **Note**: Indexes take 1-5 minutes to build after creation. The system gracefully falls back to vector-only search until text indexes are ready.

## ü§ù Integration Examples

### With LangChain
```python
from langchain_openai import ChatOpenAI
from src.memory.manager import MemoryManager

llm = ChatOpenAI(model="gpt-4")
memory = MemoryManager(db)

# Before each LLM call, retrieve relevant memories
memories = await memory.episodic.retrieve(query=user_input, agent_id="my_agent")
context = "\n".join([m.content for m in memories])

response = llm.invoke(f"Context:\n{context}\n\nUser: {user_input}")

# After LLM response, store the interaction
await memory.store_memory(
    content=f"User: {user_input}\nAssistant: {response}",
    memory_type=MemoryType.EPISODIC,
    agent_id="my_agent"
)
```

### With LangGraph
```python
from langgraph.graph import StateGraph
from src.memory.manager import MemoryManager

memory = MemoryManager(db)

def memory_node(state):
    # Retrieve memories before processing
    memories = await memory.episodic.retrieve(
        query=state["input"],
        agent_id=state["agent_id"]
    )
    state["context"] = memories
    return state

# Add to your graph
workflow.add_node("memory", memory_node)
```

## üìÑ License

MIT License - Use it, modify it, ship it!

## üôè Acknowledgments

- **MongoDB**: Atlas Vector Search
- **Voyage AI**: High-quality embeddings
- **LangChain/LangGraph**: Agent frameworks

---

**Built for the AI community** üöÄ

*Clone ‚Üí Configure ‚Üí Remember Everything*
